"""Configuration options for running Spark and Shark performance tests (perf-tests)."""

import time

# Standard Configuration Options
# ----------------------------------------------------------------------------------------

# Git commit id to checkout and test. The repository location configured via SPARK_GIT_REPO and/or
# SHARK_GIT_REPO is named "origin". This ID can specify any of the following:
#     1. A git commit hash     e.g. "4af93ff3"
#     2. A branch name         e.g. "origin/branch-0.7"
#     3. A pull request        e.g. "origin/pr/675"
SPARK_COMMIT_ID = ""
SHARK_COMMIT_ID = ""

# Whether to merge this commit into master before testing. If the commit cannot be merged into
# master, the script will exit with a failure.
SPARK_MERGE_COMMIT_INTO_MASTER = False
SHARK_MERGE_COMMIT_INTO_MASTER = False

# File to write results to.
SPARK_OUTPUT_FILENAME = "spark_perf_output_%s_%s" % (
    SPARK_COMMIT_ID.replace("/", "-"), time.strftime("%Y-%m-%d_%H-%M-%S"))
SHARK_OUTPUT_FILENAME = "shark_perf_output_%s_%s" % (
    SHARK_COMMIT_ID.replace("/", "-"), time.strftime("%Y-%m-%d_%H-%M-%S"))

# Existing directories for Spark and Shark.
SPARK_HOME_DIR = "/root/spark"
SHARK_HOME_DIR = "/root/shark"

# Git repos used to clone clean copies of Spark and Shark to path/to/perf-tests/spark and
# path/to/perf-tests/shark, respectively.
SPARK_GIT_REPO = "git://github.com/mesos/spark.git"
SHARK_GIT_REPO = "git://github.com/amplab/shark.git"

# Git repo for a patched, Shark-compatible version of Hive 0.9.
HIVE_GIT_REPO = "git://github.com/amplab/hive.git -b shark-0.9"

# Before we start Spark, the files contained in the SPARK_CONF_DIR directory, such as spark-env.sh
# and the slaves file, are copied to the conf directory of the clean Spark copy cloned from
# SPARK_GIT_REPO (i.e path/to/perf-tests/spark).
# To test on your local machine, create a spark-env.sh and a slaves file with a single slave set as
# your local machine.
SPARK_CONF_DIR = SPARK_HOME_DIR + "/conf"

# The same use case as SPARK_CONF_DIR above.
SHARK_CONF_DIR = SHARK_HOME_DIR + "/conf"

# This default setting assumes we are running on the Spark EC2 AMI. Developers will probably want
# to change this to SPARK_CLUSTER_URL = "spark://localhost:7077" for testing.
SPARK_CLUSTER_URL = open("/root/spark-ec2/cluster-url", 'r').readline().strip()

# Command used to launch Scala.
SCALA_CMD = "scala"

# The default values configured below are appropriate for approximately 20 m1.xlarge nodes, in which
# each node has 15 GB of memory.
# Use this variable to scale the values (e.g. number of records in a generated dataset) if you are
# running the tests with more or fewer nodes.
SCALE_FACTOR = 1.0

assert SCALE_FACTOR > 0, "SCALE_FACTOR must be > 0."


# Test Configuration
# ----------------------------------------------------------------------------------------

class OptionSet(object):
    """Represents an option and a set of values for it to sweep over."""
    def __init__(self, name, vals, can_scale=False):
        self.name = name
        self.vals = vals
        self.can_scale = can_scale

    def scaled_vals(self, scale_factor):
        """If this class can_scale, then return scaled vals. Else return values as-is."""
        if self.can_scale:
            return [max(1, int(val * scale_factor)) for val in self.vals]
        else:
            return [val for val in self.vals]

    def to_array(self, scale_factor = 1.0):
        """
        Return array of strings each representing a command line option name/value pair.
        If can_scale is True, all values will be multipled by scale_factor before being returned.
        """
        return ["--%s=%s" % (self.name, val) for val in self.scaled_vals(scale_factor)]


class JavaOptionSet(OptionSet):
    def __init__(self, name, vals, can_scale=False):
        OptionSet.__init__(self, name, vals, can_scale)

    def to_array(self, scale_factor = 1.0):
        """Return array of strings each representing a Java option name/value pair."""
        return ["-D%s=%s" % (self.name, val) for val in self.scaled_vals(scale_factor)]

# Represents a flag-style option and a set of values that
# we will sweep over in a test run. Values can be True or False.
class FlagSet:
    def __init__(self, name, vals):
        self.name = name
        self.vals = vals
    def to_array(self, scale_factor = 1.0):
        for val in self.vals:
            assert val == True or val == False, ("FlagSet value for %s is not True or False" % 
                self.name)
        return ["--%s" % self.name if val is True else "" for val in self.vals]


# Set up OptionSets. Note that giant cross product is done over all JavaOptionsSets + OptionSets
# passed to each test which may be combinations of those set up here.

# Java options.
COMMON_JAVA_OPTS = [
    # Fraction of JVM memory used for caching RDDs.
    JavaOptionSet("spark.storage.memoryFraction", [0.66]),
    JavaOptionSet("spark.serializer", ["spark.JavaSerializer"]),
    JavaOptionSet("spark.executor.memory", ["9g"])
]

# The following options value sets are shared among all tests.
COMMON_OPTS = [
    # How many times to run each experiment - used to warm up system caches.
    # This OptionSet should probably only have a single value (i.e., length 1)
    # since it doesn't make sense to have multiple values here.
    OptionSet("num-trials", [5]),
    # The number of input partitions.
    OptionSet("num-partitions", [400], can_scale=True),
    # The number of reduce tasks.
    OptionSet("reduce-tasks", [400], can_scale=True),
    # A random seed to make tests reproducable.
    OptionSet("random-seed", [5]),
    # Input persistence strategy (can be "memory" or "disk").
    OptionSet("persistent-type", ["memory"]),
    # Whether to wait for input in order to exit the JVM.
    FlagSet("wait-for-exit", [False])
]

# The following options apply to generation of the key-value data shared by all Spark tests.
SPARK_KEY_VAL_TEST_OPTS = [
    OptionSet("num-records", [200 * 1000 * 1000], can_scale=True),
    OptionSet("unique-keys",[20 * 1000], can_scale=True),
    OptionSet("key-length", [10]),
    OptionSet("unique-values", [1000 * 1000], can_scale=True),
    OptionSet("value-length", [10])
]

# The following options apply to generation of table data shared by all Shark tests.
SHARK_TABLE_GEN_OPTS = [
    OptionSet("num-rows", [200 * 1000 * 1000], can_scale=True),
    OptionSet("num-columns", [10]),
    OptionSet("unique_rows", [20 * 1000], can_scale=True)
]

# TODO(harvey): Selectivity factor could measure the performance of stitching rows back together
#               when scanning columnar stores.
# The following option applies to scans over tables generated using SHARK_TABLE_GEN_OPTs.
SHARK_TABLE_SCAN_OPTS = [
   OptionSet("selectivity-factor", [0.5])
]

# The following option controls storage formats for cached tables. Currently, the only in-memory
# storage format for cached tables in Shark is columnar.
SHARK_TABLE_STORAGE_OPTS = [
    # Supported compression types: "rle", "dictionary", "rle-variant", and "default".
    # Tables are uncompressed by default.
    OptionSet("column-compression-type", ["default"])
]

# Test setup
# ----------------------------------------------------------------------------------------
# Set up the actual tests. Each test is represtented by a tuple: (short_name, test_cmd,
# scale_factor, list<JavaOptionSet>, list<OptionSet>).

# Set up Spark tests
SPARK_KV_OPTS = COMMON_OPTS + SPARK_KEY_VAL_TEST_OPTS

SPARK_TESTS = []

SPARK_TESTS += [("scala-agg-by-key", "spark.perf.TestRunner aggregate-by-key", SCALE_FACTOR,
    COMMON_JAVA_OPTS, SPARK_KV_OPTS)]

# Scale the input for this test by an additional 0.10.
SPARK_TESTS += [("scala-sort-by-key", "spark.perf.TestRunner sort-by-key", SCALE_FACTOR * 0.1,
    COMMON_JAVA_OPTS, SPARK_KV_OPTS)]

SPARK_TESTS += [("scala-count", "spark.perf.TestRunner count", SCALE_FACTOR, COMMON_JAVA_OPTS,
    SPARK_KV_OPTS)]

SPARK_TESTS += [("scala-count-w-fltr", "spark.perf.TestRunner count-with-filter", SCALE_FACTOR,
    COMMON_JAVA_OPTS, SPARK_KV_OPTS)]

# Set up Shark tests
SHARK_TABLE_OPTS = COMMON_OPTS + SHARK_TABLE_GEN_OPTS + SHARK_TABLE_STORAGE_OPTS

SHARK_TESTS = []

SHARK_TABLE_SCAN_OPTS = SHARK_TABLE_OPTS + SHARK_TABLE_SCAN_OPTS
SHARK_TESTS += [("table-scan-query", "shark.perf.TestRunner table-scan-query", SCALE_FACTOR, COMMON_JAVA_OPTS,
    SHARK_TABLE_OPTS)]

'''
TODO(harvey): Uncomment once these tests are supported.

SHARK_TESTS += [("sort-query", "shark.perf.TestRunner sort-query", SCALE_FACTOR, COMMON_JAVA_OPTS,
    SHARK_TABLE_OPTS)]

SHARK_TESTS += [("aggregate-query", "shark.perf.TestRunner aggregate-query", SCALE_FACTOR,
    COMMON_JAVA_OPTS, SHARK_TABLE_OPTS)]

SHARK_TESTS += [("join-query", "shark.perf.TestRunner join-query", SCALE_FACTOR, COMMON_JAVA_OPTS,
    SHARK_TABLE_OPTS)]

SHARK_TESTS += [("UDF-query", "shark.perf.TestRunner udf-query", SCALE_FACTOR, COMMON_JAVA_OPTS,
    SHARK_TABLE_OPTS)]
'''

# Advanced Configuration Options
# ----------------------------------------------------------------------------------------

# Skip downloading and building Spark, Hive and/or Shark components. Requires project to be already
# built in its respective directory.
SKIP_SPARK_PREP = False
SKIP_SHARK_PREP = False
SKIP_HIVE_PREP = False

# Skip building and packaging tests (requires perf-tests already be packaged in the target
# directory).
SKIP_TEST_PREP = False

# Skip warming up local disks.
SKIP_DISK_WARMUP = False

# Total number of bytes used to warm up each local directory.
DISK_WARMUP_BYTES = 200 * 1024 * 1024

# Number of files to create when warming up each local directory. Bytes will be evenly divided
# across files.
DISK_WARMUP_FILES = 200

# Prompt for confirmation when deleting temporary files.
PROMPT_FOR_DELETES = True
