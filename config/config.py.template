"""Configuration options for running the Spark performance tests (perf-tests)."""

import time

# Standard Configuration Options
# ----------------------------------------------------------------------------------------

# Git commit id to checkout and test. The repository location configured via SPARK_GIT_REPO is
# named "origin". This ID can specify any of the following:
#   1. A git commit hash   e.g. "4af93ff3"
#   2. A branch name       e.g. "origin/branch-0.7"
#   3. A pull request      e.g. "origin/pr/675"
COMMIT_ID = ""

# Whether to merge this commit into master before testing. If the commit cannot be merged into
# master, the script will exit with a failure.
MERGE_INTO_MASTER = False

# File to write results to.
OUTPUT_FILENAME = "spark_perf_output_%s_%s" % (
    COMMIT_ID.replace("/", "-"), time.strftime("%Y-%m-%d_%H-%M-%S"))

SPARK_GIT_REPO = "git://github.com/mesos/spark.git"

# The test framework clones its own clean copy of Spark, and then the files in this dir (e.g.
# spark-env.sh and slaves file) are copied from this directory to that Spark's conf dir before we
# start the Spark. To test on your local machine, create a spark-env.sh and a slaves file with a
# single slave set as your local machine.
SPARK_CONF_DIR = "/root/spark/conf"

# This default setting assumes we are running on the Spark EC2 AMI. Developers will probably want
# to change this to SPARK_CLUSTER_URL = "spark://localhost:7077" for testing.
SPARK_CLUSTER_URL = open("/root/spark-ec2/cluster-url", 'r').readline().strip()

# Command used to launch Scala.
SCALA_CMD = "scala"

# The default values configured below are appropriate for approximately 20 m1.xlarge nodes.
# Use this variable to scale the values if you are running the tests with more or fewer nodes.
SCALE_FACTOR = 1.0

assert SCALE_FACTOR > 0, "SCALE_FACTOR must be > 0."


# Test Configuration
# ----------------------------------------------------------------------------------------

class OptionSet(object):
  """Represents an option and a set of values for it to sweep over."""
  def __init__(self, name, vals, can_scale=False):
    self.name = name
    self.vals = vals
    self.can_scale = can_scale

  def scaled_vals(self, scale_factor):
    """If this class can_scale, then return scaled vals. Else return values as-is."""
    if self.can_scale:
      return [max(1, int(val * scale_factor)) for val in self.vals]
    else:
      return [val for val in self.vals]

  def to_array(self, scale_factor = 1.0):
    """
    Return array of strings each representing a command line option name/value pair.
    If can_scale is True, all values will be multipled by scale_factor before being returned.
    """
    return ["--%s=%s" % (self.name, val) for val in self.scaled_vals(scale_factor)]


class JavaOptionSet(OptionSet):
  def __init__(self, name, vals, can_scale=False):
    OptionSet.__init__(self, name, vals, can_scale)

  def to_array(self, scale_factor = 1.0):
    """Return array of strings each representing a Java option name/value pair."""
    return ["-D%s=%s" % (self.name, val) for val in self.scaled_vals(scale_factor)]

# Represents a flag-style option and a set of values that
# we will sweep over in a test run. Values can be True or False.
class FlagSet:
  def __init__(self, name, vals):
    self.name = name
    self.vals = vals
  def to_array(self, scale_factor = 1.0):
    for val in self.vals:
      assert val == True or val == False, "FlagSet value for %s is not True or False" % self.name
    return ["--%s" % self.name if val is True else "" for val in self.vals]


# Set up OptionSets. Note that giant cross product is done over all JavaOptionsSets + OptionSets
# passed to each test which may be combinations of those set up here.

# Java options.
COMMON_JAVA_OPTS = [
  # Fraction of JVM memory used for caching RDDs.
  JavaOptionSet("spark.storage.memoryFraction", [0.66]),
  JavaOptionSet("spark.serializer", ["spark.JavaSerializer"]),
  JavaOptionSet("spark.executor.memory", ["9g"])
]

# The following options value sets are shared among all tests.
COMMON_OPTS = [
  # How many times to run each experiment - used to warm up system caches.
  # This OptionSet should probably only have a single value (i.e., length 1)
  # since it doesn't make sense to have multiple values here.
  OptionSet("num-trials", [5]),
  # The number of input partitions.
  OptionSet("num-partitions", [400], True),
  # The number of reduce tasks.
  OptionSet("reduce-tasks", [400], True),
  # A random seed to make tests reproducable.
  OptionSet("random-seed", [5]),
  # Input persistence strategy (can be "memory" or "disk").
  OptionSet("persistent-type", ["memory"]),
  # Whether to wait for input in order to exit the JVM.
  FlagSet("wait-for-exit", [False])
]

# The following options value sets are shared among all tests of
# operations on key-value data.
KEY_VAL_TEST_OPTS = [
  OptionSet("num-records", [200 * 1000 * 1000], True),
  OptionSet("unique-keys",[20 * 1000], True),
  OptionSet("key-length", [10]),
  OptionSet("unique-values", [1000 * 1000], True),
  OptionSet("value-length", [10])
]


# Test setup
# ----------------------------------------------------------------------------------------
# Set up the actual tests. Each test is represtented by a tuple: (short_name, test_cmd,
# scale_factor, list<JavaOptionSet>, list<OptionSet>).

KV_OPTS = COMMON_OPTS + KEY_VAL_TEST_OPTS

TESTS = []

TESTS += [("scala-agg-by-key", "spark.perf.TestRunner aggregate-by-key", SCALE_FACTOR,
    COMMON_JAVA_OPTS, KV_OPTS)]

# Scale the input for this test by an additional 0.10.
TESTS += [("scala-sort-by-key", "spark.perf.TestRunner sort-by-key", SCALE_FACTOR * 0.1,
    COMMON_JAVA_OPTS, KV_OPTS)]

TESTS += [("scala-count", "spark.perf.TestRunner count", SCALE_FACTOR, COMMON_JAVA_OPTS, KV_OPTS)]

TESTS += [("scala-count-w-fltr", "spark.perf.TestRunner count-with-filter", SCALE_FACTOR,
    COMMON_JAVA_OPTS, KV_OPTS)]


# Advanced Configuration Options
# ----------------------------------------------------------------------------------------

# Skip downloading and building Spark (requires Spark already be built in the spark directory).
SKIP_SPARK_PREP = False

# Skip building and packaging tests (requires perf-tests already be packaged in the target
# directory).
SKIP_TEST_PREP = False

# Skip warming up local disks.
SKIP_DISK_WARMUP = False

# Total number of bytes used to warm up each local directory.
DISK_WARMUP_BYTES = 200 * 1024 * 1024

# Number of files to create when warming up each local directory. Bytes will be evenly divided
# across files.
DISK_WARMUP_FILES = 200

# Prompt for confirmation when deleting temporary files.
PROMPT_FOR_DELETES = True
